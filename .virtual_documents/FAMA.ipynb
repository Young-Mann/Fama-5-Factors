## 配置
API_KEY = "" # 填入自己的 Tushare API key
fetch_data = False # 是否需要在线抓取数据，若为 True，则会开始获取数据。但是，如果已有本地数据可用于读取，那建议设置为 False
STARTDATE = "20190101"; ENDMONTH = '202305'
PORTFOLIO_WEIGHT = 'mkt' # 为投资组合内的股票分配权重时的方式，市值加权为 'mkt'， 等额加权为 'equal'


import tushare as ts
import numpy as np
import pandas as pd
import time
from functools import reduce
import os
import pickle
import copy
import matplotlib.pyplot as plt
from pandas.tseries.offsets import Day,MonthEnd
from datetime import datetime, timedelta


##################################################################
############################ 获取数据 ############################
##################################################################
def get_stock_info():
    global pro
    count = 0
    df = pro.stock_basic(**{
    "ts_code": "",
    "name": "",
    "exchange": "" ,
    "market": "",
    "is_hs": "",
    "list_status": "",
}, fields=[
    "ts_code",
    "symbol",
    "name",
    "area",
    "industry",
    "market",
    "list_date",
    "list_status",
    "is_hs",
    "curr_type"
])
    count += 1
    if count >= 750:
        count = 0
        time.sleep(60)

    dic = dict(list(df.groupby(['market'], axis=0)))
    # 中小板和主板合并了，现在是：['主板', '创业板', '北交所', '科创板']
    df = pd.concat([dic['主板'], dic['创业板'], dic['科创板']])
    # print(df)
    return df

def get_return(df, savedata = True):
    global STARTDATE, pro
    count = 0; limit_per_minute = 800 
    res = []
    # limit_per_minute = 800 if which_data == 'return' or 'factor' else 500
    
    ts_code = df['ts_code']   
    for st in ts_code:
        temp = pro.monthly(**{
            "ts_code": st,
            "trade_date": "",
            "start_date": STARTDATE,
            "end_date": "",
        }, fields=[
            "ts_code",
            "trade_date",
            "pct_chg"
        ])
        res.append(temp) 
        count += 1
        if count >= limit_per_minute:
            count = 0
            time.sleep(60)        
    res = pd.concat(res, axis=0)
    res['trade_date'] = pd.to_datetime(res['trade_date'])
    if savedata:
        pickle.dump(res,open(r'./FAMA5/ret_'+STARTDATE+'.txt','wb'))
    return res

def get_factors(date_list, savedata = True):
    global pro
    rcount = 0
    factor = []; count = 0; limit_per_minute = 800 
    # date_list = [i for i in set(df['trade_date'])]
    # date_list = [i.strftime("%Y%m%d") for i in set(df['trade_date'])]
    for date in date_list:
        # print(date)
        fa = pro.daily_basic(**{
            "ts_code": "",
            "trade_date": date,
        }, fields=[
            "ts_code",
            "trade_date",
            "circ_mv",
            # "total_mv",
            'pb'])       
        factor.append(fa)
        count += 1; rcount += 1
        # print(count)
        if count >= limit_per_minute:
            count = 0
            # print(rcount)
            time.sleep(60)        
    factor = pd.concat(factor, axis=0)
    factor['trade_date'] = pd.to_datetime(factor['trade_date'])
    factor['bm'] = 1/factor['pb']
    del factor['pb']
    
    if savedata:
        pickle.dump(factor,open(r'./FAMA5/factor_'+STARTDATE+'.txt','wb'))
    return factor

def get_roes(df, savedata = True):
    global STARTDATE, pro
    rcount = 0    
    qroe = []; count = 0; limit_per_minute = 500 
    for st in set(df['ts_code']):  
        df = pro.fina_indicator(**{
            "ts_code": st,
            "start_date": STARTDATE,
        }, fields=[
            "ts_code",
            "end_date",
            "q_roe",
            ])
        qroe.append(df)
        count += 1;  rcount += 1
        # print(count)
        if count >= 500:
            count = 0
            print(rcount)
            time.sleep(60)
    qroe = pd.concat(qroe, axis=0)
    roe = qroe
    roe = roe.drop_duplicates()
    roe = roe.set_index(np.arange(0,roe.shape[0],1))
    roe.rename(columns={'end_date':'trade_date'}, inplace=True)
    roe['trade_date'] = pd.to_datetime(roe['trade_date'])
    if savedata:
        pickle.dump(qroe,open(r'./FAMA5/roe_'+STARTDATE+'.txt','wb'))
    return roe

def get_assets(df, savedata = True):
    global STARTDATE, pro
    total_assets = [];count = 0;  limit_per_minute = 500 
    for st in set(df['ts_code']):  
        df = pro.balancesheet(**{
            "ts_code": st,
            "start_date": STARTDATE,
        }, fields=[
            "ts_code",
            "end_date",
            "total_assets"])
        total_assets.append(df)
        
        count += 1
        # print(count)
        if count >= limit_per_minute:
            count = 0
            time.sleep(60)   
    total_assets = pd.concat(total_assets, axis=0)
    total_assets = total_assets.drop_duplicates()
    total_assets['end_date'] = pd.to_datetime(total_assets['end_date'])

    ## 计算增长率
    
    group = total_assets.groupby('ts_code')
    # ks = []
    vs = []
    for k,v in group:
        v['total_assets'] = v['total_assets'].diff(-1) / v['total_assets'].shift(-1)
        vs.append(v)
    g_asset = pd.concat(vs, axis=0)
    g_asset.rename(columns={'end_date':'trade_date'}, inplace=True)
    g_asset['trade_date'] = pd.to_datetime(g_asset['trade_date'])
    if savedata:
        pickle.dump(total_assets,open(r'./FAMA5/total_assets'+ r'_' + STARTDATE+'.txt','wb'))
        pickle.dump(g_asset,open(r'./FAMA5/growth_assets'+ r'_' + STARTDATE+'.txt','wb'))
    return g_asset
    
def get_rf():
    global STARTDATE, pro
    df_shibor = pro.shibor(start_date=STARTDATE, end_date = '20230531')
    df_shibor['trade_date'] = pd.to_datetime(df_shibor['date'])
    r_f = df_shibor.resample('M', on='trade_date').last()
    r_f['r_f'] = r_f['3m']/100
    r_f = r_f.loc[:,['r_f']]
    r_f = r_f.reset_index()
    r_f['trade_date'] = r_f['trade_date'].apply(lambda x : x.strftime("%Y-%m"))
    r_f = r_f.set_index('trade_date')
    return r_f


##################################################################
############################ 载入数据 ############################
##################################################################
def load_data(path):
    global STARTDATE
    f = open(r'./example_data/' + path + r'_' + STARTDATE + '.txt','rb')
    res = pickle.load(f)
    res = res.set_index(np.arange(0,res.shape[0],1))
    # print(res.columns)
    if path == 'roe':
        res.rename(columns={'end_date':'trade_date'}, inplace=True)

    # res['trade_date'] = pd.to_datetime(res['trade_date']).apply(lambda x : x.strftime("%Y-%m"))
    res['trade_date'] = pd.to_datetime(res['trade_date'])
    f.close()
    return res

##################################################################
############################ 处理数据 ############################
##################################################################
# 缩尾处理
def winsorize(s):
    up_q = s.quantile(0.99)
    low_q = s.quantile(0.01)
    s = np.where(s > up_q, up_q, s)
    s = np.where(s < low_q, low_q, s)
    upper = s.mean() + s.std() * 3
    low = s.mean() - s.std() * 3
    s = np.where(s > upper, upper, s)
    s = np.where(s < low, low, s)
    return s

# 因子分组
def get_label(df, f1, f1_label, date, f1_group, **kwargs):
    if f1_group == 3:
        df[f1_label] = 2
        df.loc[
            df.groupby(date, group_keys=False)[f1].apply(lambda x: x > x.quantile(0.7)), f1_label] = 3
        df.loc[
            df.groupby(date, group_keys=False)[f1].apply(lambda x: x < x.quantile(0.3)), f1_label] = 1
    else:
        df[f1_label] = df.groupby(date, group_keys=False)[f1].apply(
            lambda x: np.ceil(x.rank() / (len(x) / f1_group))
        )
    df[f1_label] = df[f1_label].apply(lambda x: f1_label + str(int(x)))
    return df

def prod(lst):
    res = 1
    for i in lst:
        res *= (1+i)
    return res

# 合并数据
def merge_df(ret,factor,roe,g_asset):
    df_ret_factor = pd.merge(ret,factor,how='outer',on=['ts_code','trade_date'])
    df_roe_asset = pd.merge(roe,g_asset,how='outer',on=['ts_code','trade_date'])
    df_all = pd.merge(df_ret_factor,df_roe_asset,how='outer',on=['ts_code','trade_date'])
    # df_all = pd.merge(df_all, r_f, how='left', on=['trade_date'])
    return df_all

# 删除小市值
def delete_smallsize(df, quantile = 0.3):
    global ENDMONTH
    temp = df.copy()
    for k, v in sorted(df.groupby('trade_date')['MKT']):
        if k == ENDMONTH:
            print('jump')
            continue
        least_index = v[v < v.quantile(0.3)].index - 1 # 根据前一个月的市值，删除下一个月的数据
        # print('{time} 市值处于最后 {quantile} 的股票索引为：{index}'
        #       .format(time = k, quantile = quantile, index = least_index))
        temp = temp.drop(axis=0, index=least_index)
    return temp


## 画图
def plot_series(df, file_name):
    plt.rcParams["font.sans-serif"] = ['Microsoft YaHei']
    plt.figure(figsize=(20, 10))
    for c in df.columns:
        plt.plot(
            df.index, (df[c] + 1).cumprod(), linewidth=2,
            alpha=0.7, ls='--', label=f'{c}')
    plt.xticks(fontsize=10, rotation=60)
    plt.yticks(fontsize=18)
    plt.xlabel('日期', fontsize=24)
    plt.ylabel('累计收益', fontsize=24, rotation=90)
    plt.grid(axis='y')
    plt.legend(loc='upper left', fontsize=24)
    plt.savefig(f'.\\{file_name}', dpi=500)
    plt.show()

## 用到的所有函数

# 计算五因子
def fama_french_five_factor(
        df, size, value, profit, invest, ret, date, size_group=2, value_group=3, profit_group=3, invest_group=3,
        ret_type='mkt', **kwargs
):
    """
    根据给定的数据源和因子列名生成此数据的五因子序列
    Args:
        df: 数据源
        size: 总市值列名
        value: 账面市值比列名
        profit: 盈利变量列名
        invest: 投资变量列名
        ret: 收益率列名
        date: 日期列名
        size_group: 规模因子分组数
        value_group: 价值因子分组数
        profit_group: 盈利因子分组数
        invest_group: 投资因子分组数
        ret_type: 组合内股票加权方式，mkt:市值加权, equal:等权重
        **kwargs: 需给定method参数，classical即为经典2 * 3分组模式

    Returns: 五因子的收益时间序列，市场因子未减去无风险利率

    """
    if kwargs['method'] not in ['classical', 'simple']:
        raise ValueError("Parameter 'method' is not in ['classical', 'simple']")

    if kwargs['method'] == 'classical' and (size_group != 2 or value_group != 3 or profit_group !=3 or invest_group != 3):
        raise ValueError("Please Check Parameter group, This is not classical method")

    # 为每个因子进行独立分组
    size_label = size + '_G'
    value_label = value + '_G'
    profit_label = profit + '_G'
    invest_label = invest + '_G'
    df = get_label(df, f1=size, f1_label=size_label, date=date, f1_group=size_group, **kwargs)
    df = get_label(df, f1=value, f1_label=value_label, date=date, f1_group=value_group, **kwargs)
    df = get_label(df, f1=profit, f1_label=profit_label, date=date, f1_group=profit_group, **kwargs)
    df = get_label(df, f1=invest, f1_label=invest_label, date=date, f1_group=invest_group, **kwargs)

    # 计算18个组合的加权收益率
    factor_lst = []
    for double_label, label in zip(['value_double', 'profit_double', 'invest_double'],
                                   [value_label, profit_label, invest_label]):
        df[double_label] = df[[size_label, label]].apply(
            lambda x: x[size_label] + '/' + x[label], axis=1
        )
        print(double_label, label)
        if ret_type == 'mkt':
            ret_series = df.groupby([date, double_label]).apply(
                lambda x: (x[ret] * x[size] / x[size].sum()).sum()
            ).unstack(double_label)
        elif ret_type == 'equal':
            ret_series = df.groupby([date, double_label]).apply(
                lambda x: x[ret].mean()
            ).unstack(double_label)
        else:
            raise ValueError("Parameter 'ret_type' is not in ['mkt', 'equal']")
        factor_lst.append(ret_series)
        # print(factor_lst)
    factor_ret = pd.concat(factor_lst, axis=1)
    print(factor_ret)
    factor_ret.fillna(method='bfill', inplace=True)
    factor_ret.reset_index(inplace=True)
    factor_ret[date] = factor_ret[date].shift(-1)
    factor_ret.dropna(inplace=True)
    factor_ret.set_index([date], inplace=True)

    # 计算价值因子
    long_hml = [c for c in factor_ret.columns if (value_label+str(int(value_group)) in c) and (size_label in c)]
    short_hml = [c for c in factor_ret.columns if (value_label + str(1) in c) and (size_label in c)]
    factor_ret['HML'] = factor_ret[long_hml].mean(axis=1) - factor_ret[short_hml].mean(axis=1)
    print(long_hml)
    
    # 计算盈利因子
    long_rmw = [c for c in factor_ret.columns if (profit_label+str(int(profit_group)) in c) and (size_label in c)]
    short_rmw = [c for c in factor_ret.columns if (profit_label+str(1) in c) and (size_label in c)]
    factor_ret['RMW'] = factor_ret[long_rmw].mean(axis=1) - factor_ret[short_rmw].mean(axis=1)

    # 计算投资因子
    long_cma = [c for c in factor_ret.columns if (invest_label+str(1) in c) and (size_label in c)]
    short_cma = [c for c in factor_ret.columns if (invest_label+str(int(invest_group)) in c) and (size_label in c)]
    factor_ret['CMA'] = factor_ret[long_cma].mean(axis=1) - factor_ret[short_cma].mean(axis=1)

    # 计算规模因子
    flag = True
    for other_label in [value_label, profit_label, invest_label]:
        long_smb = [c for c in factor_ret.columns if (size_label+str(1) in c) and (other_label in c)]
        short_smb = [c for c in factor_ret.columns if (size_label+str(int(size_group)) in c) and (other_label in c)]
        tmp_smb = factor_ret[long_smb].mean(axis=1) - factor_ret[short_smb].mean(axis=1)
        if flag:
            smb = tmp_smb.copy()
            flag = False
            continue
        smb = smb + tmp_smb
    smb = smb / 3
    factor_ret['SMB'] = smb

    # 计算市场因子
    mkt = df.groupby(date).apply(lambda x: (x[ret] * x[size] / x[size].sum()).sum())
    mkt.rename('MARKET', inplace=True)
    factor_ret = pd.concat([mkt, factor_ret], axis=1)
    factor_ret['MARKET'] = factor_ret['MARKET'].shift(1)
    return factor_ret[['MARKET', 'SMB', 'HML', 'RMW', 'CMA']]





if __name__ == '__main__':
    pro = ts.pro_api(API_KEY)
    date_list = [] # 存储交易日的日期信息，主要用于下面的 get_factors() 函数
    date_list += (pro.trade_cal(exchange='SZSE', start_date=STARTDATE,is_open='1')['cal_date'].tolist())
    date_list += (pro.trade_cal(exchange='SSE', start_date=STARTDATE,is_open='1')['cal_date'].tolist())
    date_list = list(set(date_list))

    r_f = get_rf() #获取无风险利率
    
    df_stock_info = get_stock_info();  # 获取股票基础信息，默认是获取北交所以外的股票信息
    if fetch_data:
        count = 0 # 记录当前爬取的数据条数。因为 Tushare 限制每分钟爬取的数据条目数量，所以需要在即将超出每分钟限额前休眠 1 分钟
        df_return = load_data('ret')
        df_return = get_return(df_stock_info)
        df_factors = get_factors(date_list)
        df_roes = get_roes(df_return)
        df_assets = get_assets(df_return)

    # 本地加载数据
    ret = load_data('ret')
    factor = load_data('factor')
    factor.drop(factor[factor['ts_code'].apply(lambda x : x.split('.')[1] == 'BJ')].index,inplace=True) # 删掉 factor 中北交所的股票
    factor = factor.groupby('ts_code').resample('M', on='trade_date').last() # 一个月内有许多个单日信息。由于是每月换一次仓位，所以这里就把每月最后一天的数据作为这个月的数据
    factor.index = factor.index.droplevel(); factor = factor.reset_index()
    roe = load_data('roe')
    g_asset = load_data('growth_assets')

    # 将 trade_date 的格式设置为 YY-MM 格式，省略了年月日中的日。也就是说，2019年1月1日的数据会被表示为：2019-01
    ret['trade_date'] = ret['trade_date'].apply(lambda x : x.strftime("%Y-%m"))
    factor['trade_date'] = factor['trade_date'].apply(lambda x : x.strftime("%Y-%m"))
    roe['trade_date'] = roe['trade_date'].apply(lambda x : x.strftime("%Y-%m"))
    g_asset['trade_date'] = g_asset['trade_date'].apply(lambda x : x.strftime("%Y-%m"))





##################################################################
####################### 合并四个 Dataframe #######################
##################################################################
df_all = merge_df(ret,factor,roe,g_asset)
df_all.rename(columns = {'pct_chg': 'RETURN',
                            'circ_mv': 'MKT',
                            # 'total_mv': 'MKT',
                            'bm': 'BM',
                            'q_roe': 'ROE',
                            'total_assets':'INV',
                            },inplace = True)
print('合并完毕')

##################################################################
##################### 删除每一期的小市值股票 #####################
##################################################################
df_all = delete_smallsize(df_all, 0.3) 
print('小市值删除完毕')

##################################################################
################### 删除新上市股票半年的数据 #####################
##################################################################
from dateutil.relativedelta import relativedelta
new_stock = df_stock_info.loc[df_stock_info['list_date']>=STARTDATE,['ts_code','list_date']]
new_stock.list_date = new_stock.list_date.astype('string')
# 需要删除上市后一年的数据，因此需要确认上市一年后的月份
new_stock.list_date = new_stock.list_date.apply(lambda x : datetime.strptime(x, "%Y%m%d") + relativedelta(years = 0, months = 7))
new_stock.list_date = new_stock.list_date.apply(lambda x : datetime.strftime(x, "%Y-%m"))
new_code = new_stock['ts_code']; new_date = new_stock['list_date']
new_dict = dict(zip(new_code,new_date))

delete_idx = []
new_df = df_all[df_all['ts_code'].isin(new_code)]
for k,v in new_df.groupby('ts_code'):
    delete_date = new_dict[k]
    # print(k,delete_date)
    idx = v[v['trade_date'] < delete_date].index.tolist()
    # print(idx)
    delete_idx.append(idx)
from itertools import chain
delete_idx = list(chain(*delete_idx))

df_all.drop(index = delete_idx, inplace=True)
print('新上市公司半年的数据删除完毕')


##################################################################
########################### 处理极端值 ###########################
##################################################################
df_all['RETURN'] = winsorize(df_all['RETURN']) # 缩尾，剔除极值

##################################################################
##################### 删除每一期的小市值股票 #####################
##################################################################
df_all['temp'] = df_all['ts_code'].copy() # temp 用于后续的 groupby
df_all = df_all.groupby('temp').fillna(method = 'bfill') # trade_date 降序排序，所以需要 后向填充缺失值 ，用千前一期的数据填充当期的数据
df_all = df_all.dropna(how="any", subset=['RETURN']) # 删除缺失收益率的数据

# 对于缺失财务特征的数据，以同期其它公司的财务特征的均值填充
mean_for_nan = df_all.groupby('trade_date').mean()
# has_nan 存储了 nan 出现的位置，结构为：(行索引, 列名)
has_nan = df_all.isnull().stack()[lambda x:x].index.tolist()
for each_set in has_nan:
    row, col = each_set
    date = df_all.loc[row]['trade_date']
    # print(date,col)
    df_all.loc[row,col] = mean_for_nan.loc[date,col]


df_all





## FAMA-5
if __name__ == '__main__':
    f5 = fama_french_five_factor(
        df_all, size='MKT', value='BM', profit='ROE', invest='INV', ret='RETURN', date='trade_date',
        size_group=2, value_group=3, profit_group=3, invest_group=3, ret_type=PORTFOLIO_WEIGHT, method='classical'
    )
    
    fama5 = pd.concat([f5,r_f], axis=1,join='inner')
    fama5['MARKET'] = fama5['MARKET'] - fama5['r_f']
    # fama5['pct_chg'] = fama5['pct_chg'] - fama5['r_f']
    fama5.drop(columns=['r_f'], inplace=True)
    fama5.fillna(0, inplace=True)
    # fama5.set_index('trade_date', inplace=True)
    print(fama5)




fama5


import statsmodels.api as sm
y = ret.groupby('trade_date')['pct_chg'].mean() - r_f['r_f']
result = sm.OLS(y, sm.add_constant(fama5.loc[:,['MARKET', "SMB", "HML", "RMW", "CMA"]])).fit()
result.summary()


plot_series(fama5, file_name='五因子累计收益.png')
for col in fama5.columns:
    print("{} 的投资收益累计增长了: {} 倍".format(col,prod(fama5[col])))


df_all





## 计算 18 个组合每期的组合收益率
def get_each_group_return(df_all,group_name_lst):
    global PORTFOLIO_WEIGHT
    res_lst = []
    # res_df = pd.DataFrame(columns=['trade_date','group_name','RETURN'])
    for group_name in group_name_lst:
        for k, sub_df in df_all.groupby(['trade_date', group_name]):
            if PORTFOLIO_WEIGHT == 'mkt':
                ret = ((sub_df['RETURN'] * sub_df['MKT'] / sub_df['MKT'].sum()).sum())
            else:
                ret =  ((sub_df['RETURN'] / sub_df.shape[0]).sum())
            res = k.__add__((ret,))
            res_lst.append(res)
    temp_df = pd.DataFrame.from_records(res_lst, columns = ['trade_date','group_name','RETURN'])
    return temp_df

group_name_lst = ['value_double', 'profit_double','invest_double']
group_return = get_each_group_return(df_all,group_name_lst)


## 计算 18 个组合每期的公司特征取值均值
group_factor = pd.DataFrame()
for group_name in group_name_lst:
    df_temp = df_all.groupby(['trade_date', group_name]).mean(numeric_only=True).reset_index().rename(columns={group_name:'group_name'})
    del df_temp['RETURN']
    group_factor = pd.concat([group_factor,df_temp])
    print(group_factor)

## 合并两组数据
group_data = group_return.merge(group_factor, how='inner', on=['trade_date','group_name'])

group_data





from scipy import stats
group_data[['MKT','BM','ROE','INV']] = group_data.groupby('trade_date',group_keys=False)[['MKT','BM','ROE','INV']].apply(lambda x : stats.zscore(x))
group_data.rename(columns = {'MKT':"MC","ROE":"OP"},inplace=True)
group_data





coef_lst = []; coef_index= [ ]
for k, v in group_data.groupby('trade_date'):
    model_temp = sm.OLS(v['RETURN'], sm.add_constant(v.loc[:,['MC', "BM", "OP", "INV"]])).fit()
    print(k)
    temp = model_temp.params
    del temp['const']
    print(temp)
    coef_lst.append(temp)
    coef_index.append(k)
coef_df = pd.DataFrame(coef_lst, index = coef_index)


coef_df


plot_series(coef_df, file_name='五因子累计收益-截面回归.png')
for col in coef_df.columns:
    print("{} 的投资收益累计增长了: {} 倍".format(col,prod(coef_df[col])))
